{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10: Final Project - Comprehensive Seoul Heatwave Analysis System\n",
    "\n",
    "**Instructor**: Sohn Chul\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "In this final project, you will integrate all the skills and knowledge gained throughout the course to build a comprehensive heatwave analysis and prediction system for Seoul. This system will:\n",
    "\n",
    "1. Process real S-DoT sensor data\n",
    "2. Calculate KMA heat index values\n",
    "3. Perform spatial-temporal analysis\n",
    "4. Identify urban heat islands\n",
    "5. Build predictive models\n",
    "6. Create interactive visualizations\n",
    "7. Generate automated reports\n",
    "8. Provide real-time monitoring capabilities\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By completing this project, you will demonstrate:\n",
    "- Ability to work with real-world climate data\n",
    "- Proficiency in applying the KMA heat index formula\n",
    "- Skills in building end-to-end data science pipelines\n",
    "- Capability to create production-ready analysis systems\n",
    "- Understanding of climate change impact assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: System Architecture and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import folium\n",
    "from folium import plugins\n",
    "import streamlit as st\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, IsolationForest\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Time Series\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeoulHeatwaveAnalysisSystem:\n",
    "    \"\"\"\n",
    "    Comprehensive Seoul Heatwave Analysis System\n",
    "    Integrates all course components into a production-ready system.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config_path: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize the analysis system.\n",
    "        \n",
    "        Parameters:\n",
    "        config_path: Path to configuration file (JSON)\n",
    "        \"\"\"\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.config = self._load_config(config_path)\n",
    "        self.data = None\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "        \n",
    "    def _load_config(self, config_path: Optional[str]) -> Dict:\n",
    "        \"\"\"Load system configuration.\"\"\"\n",
    "        default_config = {\n",
    "            'data_path': '../data/s-dot/',\n",
    "            'output_path': '../outputs/',\n",
    "            'model_path': '../models/',\n",
    "            'heat_index_threshold': 33,\n",
    "            'analysis_period': {'start': '2025-04-01', 'end': '2025-08-31'},\n",
    "            'districts': ['Gangnam', 'Gangdong', 'Gangbuk', 'Gangseo', 'Gwanak',\n",
    "                         'Gwangjin', 'Guro', 'Geumcheon', 'Nowon', 'Dobong',\n",
    "                         'Dongdaemun', 'Dongjak', 'Mapo', 'Seodaemun', 'Seocho',\n",
    "                         'Seongdong', 'Seongbuk', 'Songpa', 'Yangcheon', 'Yeongdeungpo',\n",
    "                         'Yongsan', 'Eunpyeong', 'Jongno', 'Jung', 'Jungnang']\n",
    "        }\n",
    "        \n",
    "        if config_path and Path(config_path).exists():\n",
    "            with open(config_path, 'r') as f:\n",
    "                user_config = json.load(f)\n",
    "                default_config.update(user_config)\n",
    "        \n",
    "        return default_config\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_wet_bulb_temperature(Ta: np.ndarray, RH: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculate wet-bulb temperature using Stull's formula.\n",
    "        \n",
    "        Parameters:\n",
    "        Ta: Air temperature (°C)\n",
    "        RH: Relative humidity (%)\n",
    "        \n",
    "        Returns:\n",
    "        Tw: Wet-bulb temperature (°C)\n",
    "        \"\"\"\n",
    "        Tw = (Ta * np.arctan(0.151977 * (RH + 8.313659)**0.5) + \n",
    "              np.arctan(Ta + RH) - \n",
    "              np.arctan(RH - 1.67633) + \n",
    "              0.00391838 * RH**1.5 * np.arctan(0.023101 * RH) - \n",
    "              4.686035)\n",
    "        return Tw\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_heat_index_kma(Ta: np.ndarray, RH: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculate heat index using Korea Meteorological Administration (KMA) formula.\n",
    "        \n",
    "        Parameters:\n",
    "        Ta: Air temperature (°C)\n",
    "        RH: Relative humidity (%)\n",
    "        \n",
    "        Returns:\n",
    "        HI: Heat index (°C)\n",
    "        \"\"\"\n",
    "        Tw = SeoulHeatwaveAnalysisSystem.calculate_wet_bulb_temperature(Ta, RH)\n",
    "        HI = (-0.2442 + 0.55399 * Tw + 0.45535 * Ta - \n",
    "              0.0022 * Tw**2 + 0.00278 * Tw * Ta + 3.0)\n",
    "        return HI\n",
    "    \n",
    "    def load_data(self, data_source: str = 'synthetic') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load data from specified source.\n",
    "        \n",
    "        Parameters:\n",
    "        data_source: 'synthetic' or 'real' (S-DoT data)\n",
    "        \n",
    "        Returns:\n",
    "        DataFrame with loaded data\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"Loading data from {data_source} source\")\n",
    "        \n",
    "        if data_source == 'synthetic':\n",
    "            self.data = self._generate_synthetic_data()\n",
    "        else:\n",
    "            self.data = self._load_sdot_data()\n",
    "        \n",
    "        # Calculate KMA heat index\n",
    "        self.data['heat_index'] = self.calculate_heat_index_kma(\n",
    "            self.data['temperature'].values,\n",
    "            self.data['humidity'].values\n",
    "        )\n",
    "        \n",
    "        self.logger.info(f\"Data loaded: {len(self.data)} records\")\n",
    "        return self.data\n",
    "    \n",
    "    def _generate_synthetic_data(self) -> pd.DataFrame:\n",
    "        \"\"\"Generate synthetic data for demonstration.\"\"\"\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        date_range = pd.date_range(\n",
    "            start=self.config['analysis_period']['start'],\n",
    "            end=self.config['analysis_period']['end'],\n",
    "            freq='H'\n",
    "        )\n",
    "        \n",
    "        data_list = []\n",
    "        for district in self.config['districts'][:10]:  # Use 10 districts for demo\n",
    "            for date in date_range:\n",
    "                hour = date.hour\n",
    "                month = date.month\n",
    "                \n",
    "                # Realistic temperature patterns\n",
    "                base_temp = 15 + (month - 4) * 3\n",
    "                daily_variation = 8 * np.sin((hour - 6) * np.pi / 12) if 6 <= hour <= 18 else -2\n",
    "                temp = base_temp + daily_variation + np.random.normal(0, 2)\n",
    "                \n",
    "                # Humidity patterns\n",
    "                base_humidity = 70 - (month - 4) * 5\n",
    "                humidity = base_humidity - daily_variation * 2 + np.random.normal(0, 5)\n",
    "                humidity = np.clip(humidity, 20, 95)\n",
    "                \n",
    "                # Air quality\n",
    "                pm25 = 20 + np.random.exponential(10)\n",
    "                pm10 = pm25 * 1.5 + np.random.normal(0, 5)\n",
    "                \n",
    "                data_list.append({\n",
    "                    'timestamp': date,\n",
    "                    'district': district,\n",
    "                    'temperature': temp,\n",
    "                    'humidity': humidity,\n",
    "                    'pm25': pm25,\n",
    "                    'pm10': pm10,\n",
    "                    'lat': 37.5665 + np.random.uniform(-0.1, 0.1),\n",
    "                    'lon': 126.9780 + np.random.uniform(-0.15, 0.15)\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(data_list)\n",
    "    \n",
    "    def _load_sdot_data(self) -> pd.DataFrame:\n",
    "        \"\"\"Load real S-DoT sensor data.\"\"\"\n",
    "        # Implementation for loading real S-DoT data\n",
    "        # This would read from the actual CSV files in s-dot folder\n",
    "        pass\n",
    "    \n",
    "    def perform_eda(self) -> Dict:\n",
    "        \"\"\"Perform exploratory data analysis.\"\"\"\n",
    "        self.logger.info(\"Performing exploratory data analysis\")\n",
    "        \n",
    "        eda_results = {\n",
    "            'basic_stats': self.data.describe(),\n",
    "            'missing_values': self.data.isnull().sum(),\n",
    "            'heat_index_stats': {\n",
    "                'mean': self.data['heat_index'].mean(),\n",
    "                'max': self.data['heat_index'].max(),\n",
    "                'min': self.data['heat_index'].min(),\n",
    "                'std': self.data['heat_index'].std(),\n",
    "                'danger_count': (self.data['heat_index'] > self.config['heat_index_threshold']).sum()\n",
    "            },\n",
    "            'district_analysis': self.data.groupby('district')['heat_index'].agg(['mean', 'max', 'min', 'std']),\n",
    "            'temporal_patterns': self._analyze_temporal_patterns(),\n",
    "            'correlations': self.data[['temperature', 'humidity', 'heat_index', 'pm25', 'pm10']].corr()\n",
    "        }\n",
    "        \n",
    "        self.results['eda'] = eda_results\n",
    "        return eda_results\n",
    "    \n",
    "    def _analyze_temporal_patterns(self) -> Dict:\n",
    "        \"\"\"Analyze temporal patterns in the data.\"\"\"\n",
    "        patterns = {\n",
    "            'hourly': self.data.groupby(self.data['timestamp'].dt.hour)['heat_index'].mean(),\n",
    "            'daily': self.data.groupby(self.data['timestamp'].dt.date)['heat_index'].mean(),\n",
    "            'monthly': self.data.groupby(self.data['timestamp'].dt.month)['heat_index'].mean(),\n",
    "            'weekday': self.data.groupby(self.data['timestamp'].dt.dayofweek)['heat_index'].mean()\n",
    "        }\n",
    "        return patterns\n",
    "    \n",
    "    def identify_urban_heat_islands(self) -> pd.DataFrame:\n",
    "        \"\"\"Identify urban heat island areas.\"\"\"\n",
    "        self.logger.info(\"Identifying urban heat islands\")\n",
    "        \n",
    "        # Calculate UHI intensity for each district\n",
    "        district_avg = self.data.groupby('district')['heat_index'].mean()\n",
    "        overall_avg = self.data['heat_index'].mean()\n",
    "        \n",
    "        uhi_intensity = district_avg - overall_avg\n",
    "        uhi_df = pd.DataFrame({\n",
    "            'district': uhi_intensity.index,\n",
    "            'uhi_intensity': uhi_intensity.values,\n",
    "            'classification': pd.cut(uhi_intensity.values, \n",
    "                                    bins=[-np.inf, -1, 0, 1, 2, np.inf],\n",
    "                                    labels=['Cool Island', 'Neutral', 'Mild UHI', \n",
    "                                          'Moderate UHI', 'Severe UHI'])\n",
    "        })\n",
    "        \n",
    "        self.results['uhi'] = uhi_df\n",
    "        return uhi_df\n",
    "    \n",
    "    def build_prediction_models(self) -> Dict:\n",
    "        \"\"\"Build multiple prediction models.\"\"\"\n",
    "        self.logger.info(\"Building prediction models\")\n",
    "        \n",
    "        # Prepare features\n",
    "        feature_cols = ['temperature', 'humidity', 'pm25', 'pm10']\n",
    "        self.data['hour'] = self.data['timestamp'].dt.hour\n",
    "        self.data['month'] = self.data['timestamp'].dt.month\n",
    "        self.data['day_of_week'] = self.data['timestamp'].dt.dayofweek\n",
    "        \n",
    "        # Add lag features\n",
    "        for lag in [1, 3, 6, 12, 24]:\n",
    "            self.data[f'heat_index_lag_{lag}'] = self.data.groupby('district')['heat_index'].shift(lag)\n",
    "        \n",
    "        # Remove NaN values from lag features\n",
    "        data_clean = self.data.dropna()\n",
    "        \n",
    "        # Feature matrix\n",
    "        X = data_clean[feature_cols + ['hour', 'month', 'day_of_week'] + \n",
    "                      [f'heat_index_lag_{lag}' for lag in [1, 3, 6, 12, 24]]]\n",
    "        y = data_clean['heat_index']\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # 1. Random Forest\n",
    "        rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        rf_pred = rf_model.predict(X_test)\n",
    "        \n",
    "        # 2. XGBoost\n",
    "        xgb_model = xgb.XGBRegressor(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=6,\n",
    "            random_state=42\n",
    "        )\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        xgb_pred = xgb_model.predict(X_test)\n",
    "        \n",
    "        # 3. Neural Network\n",
    "        nn_model = keras.Sequential([\n",
    "            keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "            keras.layers.Dropout(0.2),\n",
    "            keras.layers.Dense(32, activation='relu'),\n",
    "            keras.layers.Dropout(0.2),\n",
    "            keras.layers.Dense(16, activation='relu'),\n",
    "            keras.layers.Dense(1)\n",
    "        ])\n",
    "        \n",
    "        nn_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "        nn_model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            validation_split=0.2,\n",
    "            verbose=0\n",
    "        )\n",
    "        nn_pred = nn_model.predict(X_test_scaled).flatten()\n",
    "        \n",
    "        # Store models\n",
    "        self.models = {\n",
    "            'random_forest': rf_model,\n",
    "            'xgboost': xgb_model,\n",
    "            'neural_network': nn_model,\n",
    "            'scaler': scaler\n",
    "        }\n",
    "        \n",
    "        # Evaluate models\n",
    "        model_results = {\n",
    "            'random_forest': {\n",
    "                'rmse': np.sqrt(mean_squared_error(y_test, rf_pred)),\n",
    "                'mae': mean_absolute_error(y_test, rf_pred),\n",
    "                'r2': r2_score(y_test, rf_pred)\n",
    "            },\n",
    "            'xgboost': {\n",
    "                'rmse': np.sqrt(mean_squared_error(y_test, xgb_pred)),\n",
    "                'mae': mean_absolute_error(y_test, xgb_pred),\n",
    "                'r2': r2_score(y_test, xgb_pred)\n",
    "            },\n",
    "            'neural_network': {\n",
    "                'rmse': np.sqrt(mean_squared_error(y_test, nn_pred)),\n",
    "                'mae': mean_absolute_error(y_test, nn_pred),\n",
    "                'r2': r2_score(y_test, nn_pred)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.results['models'] = model_results\n",
    "        return model_results\n",
    "    \n",
    "    def detect_anomalies(self) -> pd.DataFrame:\n",
    "        \"\"\"Detect anomalous heat events.\"\"\"\n",
    "        self.logger.info(\"Detecting anomalies\")\n",
    "        \n",
    "        # Prepare data for anomaly detection\n",
    "        anomaly_features = self.data[['temperature', 'humidity', 'heat_index']].dropna()\n",
    "        \n",
    "        # Isolation Forest\n",
    "        iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "        anomalies = iso_forest.fit_predict(anomaly_features)\n",
    "        \n",
    "        # Add anomaly labels to data\n",
    "        anomaly_df = self.data.copy()\n",
    "        anomaly_df.loc[anomaly_features.index, 'anomaly'] = anomalies\n",
    "        anomaly_df['is_anomaly'] = anomaly_df['anomaly'] == -1\n",
    "        \n",
    "        # Analyze anomalies\n",
    "        anomaly_stats = {\n",
    "            'total_anomalies': anomaly_df['is_anomaly'].sum(),\n",
    "            'anomaly_rate': anomaly_df['is_anomaly'].mean(),\n",
    "            'anomaly_heat_index_mean': anomaly_df[anomaly_df['is_anomaly']]['heat_index'].mean(),\n",
    "            'normal_heat_index_mean': anomaly_df[~anomaly_df['is_anomaly']]['heat_index'].mean()\n",
    "        }\n",
    "        \n",
    "        self.results['anomalies'] = anomaly_stats\n",
    "        return anomaly_df[anomaly_df['is_anomaly']]\n",
    "    \n",
    "    def generate_report(self, output_format: str = 'html') -> str:\n",
    "        \"\"\"Generate comprehensive analysis report.\"\"\"\n",
    "        self.logger.info(f\"Generating {output_format} report\")\n",
    "        \n",
    "        if output_format == 'html':\n",
    "            return self._generate_html_report()\n",
    "        elif output_format == 'pdf':\n",
    "            return self._generate_pdf_report()\n",
    "        else:\n",
    "            return self._generate_json_report()\n",
    "    \n",
    "    def _generate_html_report(self) -> str:\n",
    "        \"\"\"Generate HTML report.\"\"\"\n",
    "        html_template = \"\"\"\n",
    "        <!DOCTYPE html>\n",
    "        <html>\n",
    "        <head>\n",
    "            <title>Seoul Heatwave Analysis Report</title>\n",
    "            <style>\n",
    "                body {{ font-family: Arial, sans-serif; margin: 40px; }}\n",
    "                h1 {{ color: #2c3e50; }}\n",
    "                h2 {{ color: #34495e; margin-top: 30px; }}\n",
    "                .metric {{ \n",
    "                    display: inline-block; \n",
    "                    padding: 15px; \n",
    "                    margin: 10px;\n",
    "                    background: #ecf0f1; \n",
    "                    border-radius: 5px;\n",
    "                }}\n",
    "                .warning {{ background-color: #e74c3c; color: white; }}\n",
    "                table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}\n",
    "                th, td {{ border: 1px solid #ddd; padding: 12px; text-align: left; }}\n",
    "                th {{ background-color: #3498db; color: white; }}\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "            <h1>Seoul Heatwave Analysis Report</h1>\n",
    "            <p>Generated: {timestamp}</p>\n",
    "            <p>Analysis Period: {start_date} to {end_date}</p>\n",
    "            <p>Instructor: Sohn Chul</p>\n",
    "            \n",
    "            <h2>Executive Summary</h2>\n",
    "            <div class=\"metric\">\n",
    "                <strong>Average Heat Index:</strong> {avg_heat_index:.1f}°C\n",
    "            </div>\n",
    "            <div class=\"metric\">\n",
    "                <strong>Maximum Heat Index:</strong> {max_heat_index:.1f}°C\n",
    "            </div>\n",
    "            <div class=\"metric {danger_class}\">\n",
    "                <strong>Danger Events:</strong> {danger_count}\n",
    "            </div>\n",
    "            \n",
    "            <h2>District Analysis</h2>\n",
    "            {district_table}\n",
    "            \n",
    "            <h2>Model Performance</h2>\n",
    "            {model_table}\n",
    "            \n",
    "            <h2>Urban Heat Islands</h2>\n",
    "            {uhi_table}\n",
    "            \n",
    "            <h2>Recommendations</h2>\n",
    "            <ul>\n",
    "                <li>Implement cooling centers in high-risk districts</li>\n",
    "                <li>Increase green space in severe UHI areas</li>\n",
    "                <li>Deploy early warning systems based on predictive models</li>\n",
    "                <li>Focus resources on vulnerable populations during peak hours</li>\n",
    "            </ul>\n",
    "            \n",
    "            <footer>\n",
    "                <p style=\"margin-top: 50px; font-size: 0.9em; color: #7f8c8d;\">\n",
    "                    Report generated using KMA Heat Index Formula | Seoul Heatwave Analysis System\n",
    "                </p>\n",
    "            </footer>\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Prepare data for the report\n",
    "        heat_stats = self.results.get('eda', {}).get('heat_index_stats', {})\n",
    "        \n",
    "        # Format tables\n",
    "        district_table = self.results.get('eda', {}).get('district_analysis', pd.DataFrame()).to_html()\n",
    "        \n",
    "        model_df = pd.DataFrame(self.results.get('models', {}))\n",
    "        model_table = model_df.T.to_html()\n",
    "        \n",
    "        uhi_table = self.results.get('uhi', pd.DataFrame()).to_html(index=False)\n",
    "        \n",
    "        # Fill template\n",
    "        report = html_template.format(\n",
    "            timestamp=datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            start_date=self.config['analysis_period']['start'],\n",
    "            end_date=self.config['analysis_period']['end'],\n",
    "            avg_heat_index=heat_stats.get('mean', 0),\n",
    "            max_heat_index=heat_stats.get('max', 0),\n",
    "            danger_count=heat_stats.get('danger_count', 0),\n",
    "            danger_class='warning' if heat_stats.get('danger_count', 0) > 100 else '',\n",
    "            district_table=district_table,\n",
    "            model_table=model_table,\n",
    "            uhi_table=uhi_table\n",
    "        )\n",
    "        \n",
    "        # Save report\n",
    "        output_path = Path(self.config['output_path']) / f\"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html\"\n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(report)\n",
    "        \n",
    "        self.logger.info(f\"Report saved to {output_path}\")\n",
    "        return str(output_path)\n",
    "    \n",
    "    def _generate_pdf_report(self) -> str:\n",
    "        \"\"\"Generate PDF report (placeholder).\"\"\"\n",
    "        # Implementation would use libraries like reportlab or weasyprint\n",
    "        pass\n",
    "    \n",
    "    def _generate_json_report(self) -> str:\n",
    "        \"\"\"Generate JSON report.\"\"\"\n",
    "        report_data = {\n",
    "            'metadata': {\n",
    "                'generated': datetime.now().isoformat(),\n",
    "                'analysis_period': self.config['analysis_period'],\n",
    "                'instructor': 'Sohn Chul'\n",
    "            },\n",
    "            'results': self.results\n",
    "        }\n",
    "        \n",
    "        output_path = Path(self.config['output_path']) / f\"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(report_data, f, indent=2, default=str)\n",
    "        \n",
    "        return str(output_path)\n",
    "    \n",
    "    def save_models(self) -> None:\n",
    "        \"\"\"Save trained models to disk.\"\"\"\n",
    "        self.logger.info(\"Saving models\")\n",
    "        \n",
    "        model_path = Path(self.config['model_path'])\n",
    "        model_path.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Save scikit-learn models\n",
    "        for name in ['random_forest', 'xgboost', 'scaler']:\n",
    "            if name in self.models:\n",
    "                with open(model_path / f\"{name}.pkl\", 'wb') as f:\n",
    "                    pickle.dump(self.models[name], f)\n",
    "        \n",
    "        # Save neural network\n",
    "        if 'neural_network' in self.models:\n",
    "            self.models['neural_network'].save(model_path / 'neural_network.h5')\n",
    "    \n",
    "    def load_models(self) -> None:\n",
    "        \"\"\"Load saved models from disk.\"\"\"\n",
    "        self.logger.info(\"Loading models\")\n",
    "        \n",
    "        model_path = Path(self.config['model_path'])\n",
    "        \n",
    "        # Load scikit-learn models\n",
    "        for name in ['random_forest', 'xgboost', 'scaler']:\n",
    "            pkl_path = model_path / f\"{name}.pkl\"\n",
    "            if pkl_path.exists():\n",
    "                with open(pkl_path, 'rb') as f:\n",
    "                    self.models[name] = pickle.load(f)\n",
    "        \n",
    "        # Load neural network\n",
    "        nn_path = model_path / 'neural_network.h5'\n",
    "        if nn_path.exists():\n",
    "            self.models['neural_network'] = keras.models.load_model(nn_path)\n",
    "    \n",
    "    def run_full_analysis(self) -> Dict:\n",
    "        \"\"\"Run complete analysis pipeline.\"\"\"\n",
    "        self.logger.info(\"Starting full analysis pipeline\")\n",
    "        \n",
    "        # 1. Load data\n",
    "        self.load_data('synthetic')\n",
    "        \n",
    "        # 2. Exploratory Data Analysis\n",
    "        self.perform_eda()\n",
    "        \n",
    "        # 3. Identify Urban Heat Islands\n",
    "        self.identify_urban_heat_islands()\n",
    "        \n",
    "        # 4. Build prediction models\n",
    "        self.build_prediction_models()\n",
    "        \n",
    "        # 5. Detect anomalies\n",
    "        self.detect_anomalies()\n",
    "        \n",
    "        # 6. Save models\n",
    "        self.save_models()\n",
    "        \n",
    "        # 7. Generate report\n",
    "        report_path = self.generate_report('html')\n",
    "        \n",
    "        self.logger.info(\"Analysis pipeline completed successfully\")\n",
    "        \n",
    "        return {\n",
    "            'status': 'success',\n",
    "            'report_path': report_path,\n",
    "            'results_summary': {\n",
    "                'records_analyzed': len(self.data),\n",
    "                'districts_covered': self.data['district'].nunique(),\n",
    "                'danger_events': self.results['eda']['heat_index_stats']['danger_count'],\n",
    "                'best_model': min(self.results['models'].items(), \n",
    "                                 key=lambda x: x[1]['rmse'])[0]\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: System Deployment and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and run the analysis system\n",
    "system = SeoulHeatwaveAnalysisSystem()\n",
    "\n",
    "# Run full analysis\n",
    "results = system.run_full_analysis()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Report saved to: {results['report_path']}\")\n",
    "print(f\"\\nResults Summary:\")\n",
    "for key, value in results['results_summary'].items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Interactive Dashboard Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization dashboard\n",
    "def create_comprehensive_dashboard(system):\n",
    "    \"\"\"Create comprehensive visualization dashboard.\"\"\"\n",
    "    \n",
    "    # Create subplots\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Heat Index Time Series',\n",
    "            'District Comparison',\n",
    "            'Hourly Patterns',\n",
    "            'Model Performance',\n",
    "            'Urban Heat Islands',\n",
    "            'Correlation Matrix'\n",
    "        ),\n",
    "        specs=[\n",
    "            [{'type': 'scatter'}, {'type': 'bar'}],\n",
    "            [{'type': 'scatter'}, {'type': 'bar'}],\n",
    "            [{'type': 'bar'}, {'type': 'heatmap'}]\n",
    "        ],\n",
    "        vertical_spacing=0.1,\n",
    "        horizontal_spacing=0.15\n",
    "    )\n",
    "    \n",
    "    # 1. Time series\n",
    "    daily_avg = system.data.groupby(system.data['timestamp'].dt.date)['heat_index'].mean()\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=daily_avg.index, y=daily_avg.values, \n",
    "                  mode='lines', name='Daily Avg Heat Index'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. District comparison\n",
    "    district_stats = system.results['eda']['district_analysis']\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=district_stats.index, y=district_stats['mean'],\n",
    "              name='Mean Heat Index'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Hourly patterns\n",
    "    hourly_patterns = system.results['eda']['temporal_patterns']['hourly']\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=hourly_patterns.index, y=hourly_patterns.values,\n",
    "                  mode='lines+markers', name='Hourly Pattern'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 4. Model performance\n",
    "    model_perf = pd.DataFrame(system.results['models'])\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=model_perf.columns, y=model_perf.loc['rmse'],\n",
    "              name='RMSE'),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # 5. Urban Heat Islands\n",
    "    uhi_data = system.results['uhi']\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=uhi_data['district'], y=uhi_data['uhi_intensity'],\n",
    "              name='UHI Intensity'),\n",
    "        row=3, col=1\n",
    "    )\n",
    "    \n",
    "    # 6. Correlation matrix\n",
    "    corr_matrix = system.results['eda']['correlations']\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(z=corr_matrix.values,\n",
    "                  x=corr_matrix.columns,\n",
    "                  y=corr_matrix.index,\n",
    "                  colorscale='RdBu'),\n",
    "        row=3, col=2\n",
    "    )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title='Seoul Heatwave Analysis Dashboard - KMA Heat Index',\n",
    "        height=1200,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and display dashboard\n",
    "dashboard = create_comprehensive_dashboard(system)\n",
    "dashboard.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Real-time Monitoring System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealTimeMonitor:\n",
    "    \"\"\"\n",
    "    Real-time monitoring system for Seoul heatwave conditions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, system: SeoulHeatwaveAnalysisSystem):\n",
    "        self.system = system\n",
    "        self.alerts = []\n",
    "        \n",
    "    def check_current_conditions(self, current_data: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Check current conditions and generate alerts.\n",
    "        \n",
    "        Parameters:\n",
    "        current_data: Dictionary with current temperature and humidity\n",
    "        \n",
    "        Returns:\n",
    "        Dictionary with analysis results and alerts\n",
    "        \"\"\"\n",
    "        # Calculate KMA heat index\n",
    "        heat_index = self.system.calculate_heat_index_kma(\n",
    "            current_data['temperature'],\n",
    "            current_data['humidity']\n",
    "        )\n",
    "        \n",
    "        # Determine alert level\n",
    "        if heat_index < 25:\n",
    "            alert_level = 'Safe'\n",
    "            color = 'green'\n",
    "        elif heat_index < 30:\n",
    "            alert_level = 'Caution'\n",
    "            color = 'yellow'\n",
    "        elif heat_index < 33:\n",
    "            alert_level = 'Warning'\n",
    "            color = 'orange'\n",
    "        else:\n",
    "            alert_level = 'Danger'\n",
    "            color = 'red'\n",
    "        \n",
    "        # Generate recommendations\n",
    "        recommendations = self._generate_recommendations(heat_index)\n",
    "        \n",
    "        # Create alert if necessary\n",
    "        if heat_index > 33:\n",
    "            alert = {\n",
    "                'timestamp': datetime.now(),\n",
    "                'heat_index': heat_index,\n",
    "                'alert_level': alert_level,\n",
    "                'district': current_data.get('district', 'Unknown'),\n",
    "                'message': f\"DANGER: Heat index {heat_index:.1f}°C exceeds safety threshold\"\n",
    "            }\n",
    "            self.alerts.append(alert)\n",
    "        \n",
    "        return {\n",
    "            'heat_index': heat_index,\n",
    "            'alert_level': alert_level,\n",
    "            'color': color,\n",
    "            'recommendations': recommendations,\n",
    "            'recent_alerts': self.alerts[-5:]  # Last 5 alerts\n",
    "        }\n",
    "    \n",
    "    def _generate_recommendations(self, heat_index: float) -> List[str]:\n",
    "        \"\"\"Generate recommendations based on heat index.\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        if heat_index < 25:\n",
    "            recommendations.append(\"Comfortable conditions for outdoor activities\")\n",
    "        elif heat_index < 30:\n",
    "            recommendations.append(\"Stay hydrated during outdoor activities\")\n",
    "            recommendations.append(\"Take frequent breaks in shade\")\n",
    "        elif heat_index < 33:\n",
    "            recommendations.append(\"Limit outdoor activities during peak hours\")\n",
    "            recommendations.append(\"Drink water frequently\")\n",
    "            recommendations.append(\"Wear light-colored, loose clothing\")\n",
    "            recommendations.append(\"Check on elderly neighbors\")\n",
    "        else:\n",
    "            recommendations.append(\"AVOID outdoor activities\")\n",
    "            recommendations.append(\"Stay in air-conditioned spaces\")\n",
    "            recommendations.append(\"Drink water every 15-20 minutes\")\n",
    "            recommendations.append(\"Seek immediate medical attention for heat-related symptoms\")\n",
    "            recommendations.append(\"Check on vulnerable populations immediately\")\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def predict_next_hours(self, hours: int = 6) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Predict heat index for the next specified hours.\n",
    "        \n",
    "        Parameters:\n",
    "        hours: Number of hours to predict\n",
    "        \n",
    "        Returns:\n",
    "        DataFrame with predictions\n",
    "        \"\"\"\n",
    "        # This would use the trained models from the system\n",
    "        # For demonstration, we'll create synthetic predictions\n",
    "        \n",
    "        current_time = datetime.now()\n",
    "        predictions = []\n",
    "        \n",
    "        for h in range(1, hours + 1):\n",
    "            future_time = current_time + timedelta(hours=h)\n",
    "            \n",
    "            # Simulate prediction (would use actual model)\n",
    "            base_heat_index = 28 + np.random.normal(0, 3)\n",
    "            hour_effect = 5 * np.sin((future_time.hour - 6) * np.pi / 12)\n",
    "            predicted_heat_index = base_heat_index + hour_effect\n",
    "            \n",
    "            predictions.append({\n",
    "                'time': future_time,\n",
    "                'predicted_heat_index': predicted_heat_index,\n",
    "                'confidence_lower': predicted_heat_index - 2,\n",
    "                'confidence_upper': predicted_heat_index + 2\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(predictions)\n",
    "\n",
    "# Test the monitoring system\n",
    "monitor = RealTimeMonitor(system)\n",
    "\n",
    "# Simulate current conditions\n",
    "current_conditions = {\n",
    "    'temperature': 35,\n",
    "    'humidity': 70,\n",
    "    'district': 'Gangnam'\n",
    "}\n",
    "\n",
    "# Check conditions\n",
    "analysis = monitor.check_current_conditions(current_conditions)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"REAL-TIME MONITORING RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Current Heat Index: {analysis['heat_index']:.1f}°C\")\n",
    "print(f\"Alert Level: {analysis['alert_level']}\")\n",
    "print(\"\\nRecommendations:\")\n",
    "for rec in analysis['recommendations']:\n",
    "    print(f\"  • {rec}\")\n",
    "\n",
    "# Get predictions\n",
    "predictions = monitor.predict_next_hours(6)\n",
    "print(\"\\nNext 6 Hours Predictions:\")\n",
    "print(predictions[['time', 'predicted_heat_index']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Project Submission Guidelines\n",
    "\n",
    "### Deliverables\n",
    "\n",
    "Your final project submission should include:\n",
    "\n",
    "1. **Code Repository**\n",
    "   - Complete Python code for the analysis system\n",
    "   - Well-documented functions and classes\n",
    "   - Requirements.txt file with dependencies\n",
    "   - README.md with setup instructions\n",
    "\n",
    "2. **Data Analysis**\n",
    "   - Processed S-DoT sensor data\n",
    "   - KMA heat index calculations\n",
    "   - Statistical analysis results\n",
    "   - Anomaly detection findings\n",
    "\n",
    "3. **Predictive Models**\n",
    "   - Trained models (saved as .pkl or .h5 files)\n",
    "   - Model evaluation metrics\n",
    "   - Feature importance analysis\n",
    "   - Cross-validation results\n",
    "\n",
    "4. **Visualizations**\n",
    "   - Interactive dashboard (Streamlit or similar)\n",
    "   - Static analysis plots\n",
    "   - Geospatial heat maps\n",
    "   - Time series visualizations\n",
    "\n",
    "5. **Final Report**\n",
    "   - Executive summary\n",
    "   - Methodology description\n",
    "   - Key findings and insights\n",
    "   - Policy recommendations\n",
    "   - Future work suggestions\n",
    "\n",
    "### Evaluation Criteria\n",
    "\n",
    "Your project will be evaluated based on:\n",
    "\n",
    "1. **Technical Implementation (40%)**\n",
    "   - Correct implementation of KMA heat index formula\n",
    "   - Code quality and organization\n",
    "   - Model performance and validation\n",
    "   - System robustness and error handling\n",
    "\n",
    "2. **Data Analysis (30%)**\n",
    "   - Thoroughness of exploratory analysis\n",
    "   - Insights from spatial-temporal patterns\n",
    "   - Urban heat island identification\n",
    "   - Anomaly detection effectiveness\n",
    "\n",
    "3. **Visualization and Communication (20%)**\n",
    "   - Quality of visualizations\n",
    "   - Dashboard usability\n",
    "   - Report clarity and completeness\n",
    "   - Presentation of findings\n",
    "\n",
    "4. **Innovation and Creativity (10%)**\n",
    "   - Novel approaches or insights\n",
    "   - Additional features beyond requirements\n",
    "   - Real-world applicability\n",
    "   - Scalability considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations on completing the Seoul Heatwave Analysis course! Through this final project, you have:\n",
    "\n",
    "✅ Integrated all course components into a comprehensive system\n",
    "✅ Applied the KMA heat index formula throughout the analysis\n",
    "✅ Built production-ready data science pipelines\n",
    "✅ Created predictive models for heat wave forecasting\n",
    "✅ Developed interactive visualizations and dashboards\n",
    "✅ Designed a real-time monitoring system\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Climate Data Analysis**: You now have the skills to work with complex climate datasets\n",
    "2. **Heat Index Calculation**: Mastery of the KMA formula and its applications\n",
    "3. **Machine Learning**: Experience building and evaluating predictive models\n",
    "4. **Visualization**: Ability to create compelling data stories\n",
    "5. **System Design**: Understanding of end-to-end data science systems\n",
    "\n",
    "### Future Directions\n",
    "\n",
    "Consider extending this project by:\n",
    "- Integrating real-time S-DoT sensor feeds\n",
    "- Implementing mobile alert systems\n",
    "- Adding social vulnerability indices\n",
    "- Incorporating satellite imagery analysis\n",
    "- Developing climate change projections\n",
    "\n",
    "### Resources for Continued Learning\n",
    "\n",
    "- Korea Meteorological Administration (KMA): http://www.kma.go.kr\n",
    "- Seoul Open Data Plaza: https://data.seoul.go.kr\n",
    "- Climate Change Knowledge Portal: https://climateknowledgeportal.worldbank.org\n",
    "- IPCC Reports: https://www.ipcc.ch\n",
    "\n",
    "Thank you for your participation in this course. Your work contributes to better understanding and mitigation of urban heat waves in Seoul and beyond.\n",
    "\n",
    "**Instructor: Sohn Chul**\n",
    "\n",
    "---\n",
    "\n",
    "*\"The best way to predict the future is to create it.\"* - Peter Drucker\n",
    "\n",
    "Good luck with your climate analysis journey!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}