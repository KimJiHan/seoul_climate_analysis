{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4: Spatial Analysis of Heatwave Patterns\n",
    "## Geographic Distribution and Hotspot Identification\n",
    "\n",
    "**Instructor**: Sohn Chul\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Learning Objectives\n",
    "\n",
    "By the end of this session, you will be able to:\n",
    "1. Create spatial visualizations of heat index data\n",
    "2. Identify urban heat islands and hotspots\n",
    "3. Perform spatial interpolation and analysis\n",
    "4. Generate interactive maps with Folium\n",
    "5. Analyze spatial patterns and clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium import plugins\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import spatial\n",
    "from scipy.interpolate import griddata\n",
    "from shapely.geometry import Point\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('RdYlBu_r')\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Sensor Location Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sensor locations\n",
    "try:\n",
    "    # Load actual sensor location file\n",
    "    sensor_locations = pd.read_excel(\n",
    "        '../../ì„œìš¸ì‹œ ë„ì‹œë°ì´í„° ì„¼ì„œ(S-DoT) í™˜ê²½ì •ë³´ ì„¤ì¹˜ ìœ„ì¹˜ì •ë³´.xlsx',\n",
    "        engine='openpyxl'\n",
    "    )\n",
    "    print(\"âœ… Sensor location data loaded successfully\")\n",
    "    print(f\"Total sensors: {len(sensor_locations)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âš ï¸ Sensor location file not found. Creating sample data...\")\n",
    "    \n",
    "    # Create sample sensor locations across Seoul\n",
    "    np.random.seed(42)\n",
    "    n_sensors = 100\n",
    "    \n",
    "    sensor_locations = pd.DataFrame({\n",
    "        'serial_number': [f'S{i:04d}' for i in range(n_sensors)],\n",
    "        'latitude': np.random.uniform(37.45, 37.65, n_sensors),\n",
    "        'longitude': np.random.uniform(126.85, 127.15, n_sensors),\n",
    "        'district': np.random.choice(\n",
    "            ['Gangnam', 'Jongno', 'Mapo', 'Seodaemun', 'Yeongdeungpo', \n",
    "             'Dongdaemun', 'Gwanak', 'Nowon', 'Songpa', 'Gangdong'],\n",
    "            n_sensors\n",
    "        ),\n",
    "        'installation_date': pd.date_range('2020-01-01', periods=n_sensors, freq='W')\n",
    "    })\n",
    "    print(f\"âœ… Created {n_sensors} sample sensor locations\")\n",
    "\n",
    "sensor_locations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(sensor_locations.longitude, sensor_locations.latitude)]\n",
    "gdf_sensors = gpd.GeoDataFrame(sensor_locations, geometry=geometry, crs='EPSG:4326')\n",
    "\n",
    "print(f\"âœ… GeoDataFrame created with {len(gdf_sensors)} sensors\")\n",
    "print(f\"CRS: {gdf_sensors.crs}\")\n",
    "print(f\"\\nBounds:\")\n",
    "print(f\"  Min Lat: {gdf_sensors.latitude.min():.4f}\")\n",
    "print(f\"  Max Lat: {gdf_sensors.latitude.max():.4f}\")\n",
    "print(f\"  Min Lon: {gdf_sensors.longitude.min():.4f}\")\n",
    "print(f\"  Max Lon: {gdf_sensors.longitude.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load and Merge Heat Index Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample heat index data for spatial analysis\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create heat index values with spatial correlation\n",
    "# Simulate urban heat island effect (higher temperatures in central areas)\n",
    "center_lat = 37.55\n",
    "center_lon = 127.0\n",
    "\n",
    "distances = np.sqrt(\n",
    "    (sensor_locations['latitude'] - center_lat)**2 + \n",
    "    (sensor_locations['longitude'] - center_lon)**2\n",
    ")\n",
    "\n",
    "# Heat index decreases with distance from center (urban heat island)\n",
    "base_heat_index = 35 - (distances * 50)  # Base temperature gradient\n",
    "noise = np.random.normal(0, 2, len(sensor_locations))  # Add some randomness\n",
    "heat_index_values = base_heat_index + noise\n",
    "\n",
    "# Clip values to realistic range\n",
    "heat_index_values = np.clip(heat_index_values, 25, 42)\n",
    "\n",
    "# Add to GeoDataFrame\n",
    "gdf_sensors['heat_index_avg'] = heat_index_values\n",
    "gdf_sensors['heat_index_max'] = heat_index_values + np.random.uniform(2, 5, len(gdf_sensors))\n",
    "gdf_sensors['heat_index_min'] = heat_index_values - np.random.uniform(2, 5, len(gdf_sensors))\n",
    "\n",
    "print(\"âœ… Heat index data added to sensors\")\n",
    "print(f\"\\nHeat Index Statistics:\")\n",
    "print(gdf_sensors[['heat_index_avg', 'heat_index_max', 'heat_index_min']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Basic Spatial Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create static map with heat index values\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 10))\n",
    "\n",
    "# Plot sensors colored by heat index\n",
    "scatter = ax.scatter(\n",
    "    gdf_sensors['longitude'], \n",
    "    gdf_sensors['latitude'],\n",
    "    c=gdf_sensors['heat_index_avg'],\n",
    "    s=100,\n",
    "    cmap='RdYlBu_r',\n",
    "    alpha=0.7,\n",
    "    edgecolors='black',\n",
    "    linewidth=0.5\n",
    ")\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(scatter, ax=ax, label='Average Heat Index (Â°C)')\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('Longitude', fontsize=12)\n",
    "ax.set_ylabel('Latitude', fontsize=12)\n",
    "ax.set_title('Spatial Distribution of Heat Index Across Seoul', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add grid\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Interactive Map with Folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base map centered on Seoul\n",
    "seoul_center = [37.5665, 126.9780]\n",
    "m = folium.Map(location=seoul_center, zoom_start=11, tiles='OpenStreetMap')\n",
    "\n",
    "# Add heat map layer\n",
    "heat_data = [[row['latitude'], row['longitude'], row['heat_index_avg']] \n",
    "             for idx, row in gdf_sensors.iterrows()]\n",
    "\n",
    "plugins.HeatMap(heat_data, radius=15, blur=10, max_zoom=1).add_to(m)\n",
    "\n",
    "# Add sensor markers with popup information\n",
    "for idx, row in gdf_sensors.iterrows():\n",
    "    # Determine color based on heat index\n",
    "    if row['heat_index_avg'] >= 40:\n",
    "        color = 'red'\n",
    "        icon = 'fire'\n",
    "    elif row['heat_index_avg'] >= 35:\n",
    "        color = 'orange'\n",
    "        icon = 'exclamation-triangle'\n",
    "    elif row['heat_index_avg'] >= 30:\n",
    "        color = 'yellow'\n",
    "        icon = 'sun'\n",
    "    else:\n",
    "        color = 'green'\n",
    "        icon = 'cloud'\n",
    "    \n",
    "    popup_text = f\"\"\"\n",
    "    <b>Sensor: {row['serial_number']}</b><br>\n",
    "    District: {row.get('district', 'Unknown')}<br>\n",
    "    Avg Heat Index: {row['heat_index_avg']:.1f}Â°C<br>\n",
    "    Max Heat Index: {row['heat_index_max']:.1f}Â°C<br>\n",
    "    Min Heat Index: {row['heat_index_min']:.1f}Â°C\n",
    "    \"\"\"\n",
    "    \n",
    "    folium.Marker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        popup=popup_text,\n",
    "        icon=folium.Icon(color=color, icon=icon, prefix='fa'),\n",
    "        tooltip=f\"Sensor {row['serial_number']}: {row['heat_index_avg']:.1f}Â°C\"\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add title\n",
    "title_html = '''\n",
    "             <h3 align=\"center\" style=\"font-size:20px\"><b>Seoul Heat Index Distribution Map</b></h3>\n",
    "             '''\n",
    "m.get_root().html.add_child(folium.Element(title_html))\n",
    "\n",
    "# Display map\n",
    "print(\"âœ… Interactive map created\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Spatial Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid for interpolation\n",
    "grid_lat = np.linspace(gdf_sensors.latitude.min(), gdf_sensors.latitude.max(), 50)\n",
    "grid_lon = np.linspace(gdf_sensors.longitude.min(), gdf_sensors.longitude.max(), 50)\n",
    "grid_lon_mesh, grid_lat_mesh = np.meshgrid(grid_lon, grid_lat)\n",
    "\n",
    "# Prepare points and values\n",
    "points = gdf_sensors[['longitude', 'latitude']].values\n",
    "values = gdf_sensors['heat_index_avg'].values\n",
    "\n",
    "# Perform interpolation using different methods\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "methods = ['nearest', 'linear', 'cubic']\n",
    "titles = ['Nearest Neighbor', 'Linear Interpolation', 'Cubic Interpolation', 'Original Points']\n",
    "\n",
    "for idx, (method, title, ax) in enumerate(zip(methods + ['points'], titles, axes.flat)):\n",
    "    if method != 'points':\n",
    "        # Interpolate\n",
    "        grid_values = griddata(points, values, (grid_lon_mesh, grid_lat_mesh), method=method)\n",
    "        \n",
    "        # Plot interpolated surface\n",
    "        im = ax.contourf(grid_lon_mesh, grid_lat_mesh, grid_values, levels=15, cmap='RdYlBu_r')\n",
    "        ax.contour(grid_lon_mesh, grid_lat_mesh, grid_values, levels=10, colors='black', alpha=0.3, linewidths=0.5)\n",
    "    else:\n",
    "        # Plot original points\n",
    "        im = ax.scatter(gdf_sensors['longitude'], gdf_sensors['latitude'], \n",
    "                       c=gdf_sensors['heat_index_avg'], s=50, cmap='RdYlBu_r', edgecolors='black', linewidth=0.5)\n",
    "    \n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.set_title(title, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add colorbar\n",
    "    plt.colorbar(im, ax=ax, label='Heat Index (Â°C)')\n",
    "\n",
    "plt.suptitle('Spatial Interpolation of Heat Index', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Hotspot Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify hotspots (areas with high heat index)\n",
    "threshold_extreme = 40  # Extreme heat\n",
    "threshold_high = 35     # High heat\n",
    "\n",
    "# Classify sensors\n",
    "gdf_sensors['heat_category'] = pd.cut(\n",
    "    gdf_sensors['heat_index_avg'],\n",
    "    bins=[0, 30, 35, 40, 50],\n",
    "    labels=['Normal', 'Moderate', 'High', 'Extreme']\n",
    ")\n",
    "\n",
    "# Count by category\n",
    "category_counts = gdf_sensors['heat_category'].value_counts()\n",
    "\n",
    "# Visualize hotspot distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Bar chart of categories\n",
    "colors = ['green', 'yellow', 'orange', 'red']\n",
    "category_counts.plot(kind='bar', ax=axes[0], color=colors)\n",
    "axes[0].set_title('Distribution of Heat Categories', fontweight='bold')\n",
    "axes[0].set_xlabel('Heat Category')\n",
    "axes[0].set_ylabel('Number of Sensors')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Spatial plot of hotspots\n",
    "for category, color in zip(['Normal', 'Moderate', 'High', 'Extreme'], colors):\n",
    "    mask = gdf_sensors['heat_category'] == category\n",
    "    axes[1].scatter(\n",
    "        gdf_sensors[mask]['longitude'],\n",
    "        gdf_sensors[mask]['latitude'],\n",
    "        c=color,\n",
    "        label=category,\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "        edgecolors='black',\n",
    "        linewidth=0.5\n",
    "    )\n",
    "\n",
    "axes[1].set_xlabel('Longitude')\n",
    "axes[1].set_ylabel('Latitude')\n",
    "axes[1].set_title('Spatial Distribution of Heat Categories', fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nðŸ“Š Hotspot Analysis Summary:\")\n",
    "print(\"=\"*40)\n",
    "for category in category_counts.index:\n",
    "    count = category_counts[category]\n",
    "    percentage = (count / len(gdf_sensors)) * 100\n",
    "    print(f\"{category:10s}: {count:3d} sensors ({percentage:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. District-Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate by district\n",
    "if 'district' in gdf_sensors.columns:\n",
    "    district_stats = gdf_sensors.groupby('district').agg({\n",
    "        'heat_index_avg': ['mean', 'std', 'min', 'max'],\n",
    "        'serial_number': 'count'\n",
    "    }).round(2)\n",
    "    \n",
    "    district_stats.columns = ['Avg Heat Index', 'Std Dev', 'Min Heat Index', \n",
    "                              'Max Heat Index', 'Sensor Count']\n",
    "    district_stats = district_stats.sort_values('Avg Heat Index', ascending=False)\n",
    "    \n",
    "    print(\"ðŸ“Š District-Level Heat Index Statistics:\")\n",
    "    print(\"=\"*60)\n",
    "    print(district_stats)\n",
    "    \n",
    "    # Visualize district comparison\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    x = np.arange(len(district_stats))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars = ax.bar(x, district_stats['Avg Heat Index'], width, \n",
    "                  label='Average', color='orange', alpha=0.7)\n",
    "    \n",
    "    # Add error bars for standard deviation\n",
    "    ax.errorbar(x, district_stats['Avg Heat Index'], \n",
    "                yerr=district_stats['Std Dev'],\n",
    "                fmt='none', color='black', capsize=5)\n",
    "    \n",
    "    ax.set_xlabel('District', fontsize=12)\n",
    "    ax.set_ylabel('Heat Index (Â°C)', fontsize=12)\n",
    "    ax.set_title('Average Heat Index by District', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(district_stats.index, rotation=45, ha='right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, value) in enumerate(zip(bars, district_stats['Avg Heat Index'])):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                f'{value:.1f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Spatial Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Prepare data for clustering\n",
    "X = gdf_sensors[['longitude', 'latitude', 'heat_index_avg']].values\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply DBSCAN clustering\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "clusters = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "# Add cluster labels to GeoDataFrame\n",
    "gdf_sensors['cluster'] = clusters\n",
    "\n",
    "# Visualize clusters\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Plot each cluster with different color\n",
    "unique_clusters = np.unique(clusters)\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(unique_clusters)))\n",
    "\n",
    "for cluster_id, color in zip(unique_clusters, colors):\n",
    "    mask = clusters == cluster_id\n",
    "    if cluster_id == -1:\n",
    "        # Noise points\n",
    "        ax.scatter(X[mask, 0], X[mask, 1], c='gray', \n",
    "                  label='Noise', s=30, alpha=0.5)\n",
    "    else:\n",
    "        ax.scatter(X[mask, 0], X[mask, 1], c=[color], \n",
    "                  label=f'Cluster {cluster_id}', s=100, alpha=0.7,\n",
    "                  edgecolors='black', linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel('Longitude', fontsize=12)\n",
    "ax.set_ylabel('Latitude', fontsize=12)\n",
    "ax.set_title('Spatial Clustering of Heat Index Patterns', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print cluster statistics\n",
    "print(\"\\nðŸ“Š Cluster Statistics:\")\n",
    "print(\"=\"*50)\n",
    "for cluster_id in unique_clusters:\n",
    "    if cluster_id != -1:\n",
    "        cluster_data = gdf_sensors[gdf_sensors['cluster'] == cluster_id]\n",
    "        print(f\"\\nCluster {cluster_id}:\")\n",
    "        print(f\"  Size: {len(cluster_data)} sensors\")\n",
    "        print(f\"  Avg Heat Index: {cluster_data['heat_index_avg'].mean():.2f}Â°C\")\n",
    "        print(f\"  Std Heat Index: {cluster_data['heat_index_avg'].std():.2f}Â°C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Spatial Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed spatial data\n",
    "output_file = '../data/processed/spatial_analysis_results.csv'\n",
    "gdf_sensors.to_csv(output_file, index=False)\n",
    "print(f\"âœ… Spatial analysis results saved to {output_file}\")\n",
    "\n",
    "# Save interactive map\n",
    "map_file = '../outputs/seoul_heat_map.html'\n",
    "m.save(map_file)\n",
    "print(f\"âœ… Interactive map saved to {map_file}\")\n",
    "\n",
    "# Generate summary report\n",
    "summary = f\"\"\"\n",
    "SPATIAL ANALYSIS SUMMARY\n",
    "========================\n",
    "Analysis Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')}\n",
    "\n",
    "Sensor Coverage:\n",
    "- Total Sensors: {len(gdf_sensors)}\n",
    "- Geographic Extent:\n",
    "  * Latitude: {gdf_sensors.latitude.min():.4f} to {gdf_sensors.latitude.max():.4f}\n",
    "  * Longitude: {gdf_sensors.longitude.min():.4f} to {gdf_sensors.longitude.max():.4f}\n",
    "\n",
    "Heat Index Statistics:\n",
    "- Average: {gdf_sensors['heat_index_avg'].mean():.2f}Â°C\n",
    "- Maximum: {gdf_sensors['heat_index_max'].max():.2f}Â°C\n",
    "- Minimum: {gdf_sensors['heat_index_min'].min():.2f}Â°C\n",
    "\n",
    "Hotspot Analysis:\n",
    "{category_counts.to_string()}\n",
    "\n",
    "Clustering Results:\n",
    "- Number of Clusters: {len(unique_clusters[unique_clusters != -1])}\n",
    "- Noise Points: {sum(clusters == -1)}\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Assignment\n",
    "\n",
    "### Week 4 Tasks:\n",
    "\n",
    "1. **Spatial Visualization** (25 points)\n",
    "   - Create at least 3 different types of spatial visualizations\n",
    "   - Include both static and interactive maps\n",
    "   - Add proper legends and color scales\n",
    "\n",
    "2. **Interpolation Analysis** (25 points)\n",
    "   - Compare different interpolation methods\n",
    "   - Evaluate interpolation accuracy using cross-validation\n",
    "   - Create continuous heat surface maps\n",
    "\n",
    "3. **Hotspot Identification** (25 points)\n",
    "   - Identify and map urban heat islands\n",
    "   - Perform statistical hotspot analysis\n",
    "   - Calculate spatial autocorrelation metrics\n",
    "\n",
    "4. **District Comparison** (25 points)\n",
    "   - Aggregate data by administrative boundaries\n",
    "   - Compare heat patterns across districts\n",
    "   - Identify vulnerable areas\n",
    "\n",
    "### Bonus Challenge:\n",
    "- Implement Getis-Ord Gi* statistic for hotspot detection\n",
    "- Create an animated map showing temporal changes\n",
    "- Integrate demographic data for vulnerability assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this week, we covered:\n",
    "- âœ… Spatial data handling with GeoPandas\n",
    "- âœ… Interactive mapping with Folium\n",
    "- âœ… Spatial interpolation techniques\n",
    "- âœ… Hotspot and cluster analysis\n",
    "- âœ… District-level aggregation\n",
    "\n",
    "### Next Week Preview:\n",
    "**Week 5: Temporal Pattern Analysis**\n",
    "- Time series decomposition\n",
    "- Trend and seasonality analysis\n",
    "- Diurnal and weekly patterns\n",
    "- Temporal forecasting\n",
    "\n",
    "### Resources:\n",
    "- [GeoPandas Documentation](https://geopandas.org/)\n",
    "- [Folium Documentation](https://python-visualization.github.io/folium/)\n",
    "- [Spatial Analysis in Python](https://geographicdata.science/book/intro.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**End of Week 4**\n",
    "\n",
    "*Instructor: Sohn Chul*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}